{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c6bd00-178c-44ec-bf1f-2e99d3f23acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/damian/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in /home/damian/.local/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: pandas in /home/damian/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in /home/damian/.local/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: joblib in /home/damian/.local/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/lib/python3/dist-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/damian/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/damian/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/damian/.local/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/damian/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/damian/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5254628-9c29-4fa9-890d-e01aafaeecb3",
   "metadata": {},
   "source": [
    "After installing, you need to import (activate) the packages every\n",
    "session:\n",
    "\n",
    "## Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b4a68b-40b4-4679-b771-ce11139f8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages and dictionary analysis\n",
    "import os\n",
    "import tarfile\n",
    "import bz2\n",
    "import urllib.request\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "import joblib\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supervised text classification\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "# import eli5\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22515395-b1b6-4acf-bf82-e95a4b2ed525",
   "metadata": {},
   "source": [
    "In earlier chapters, you learned about both supervised and unsupervised\n",
    "machine learning as well about dealing with texts. This chapter brings\n",
    "together these elements and discusses how to combine them to\n",
    "automatically analyze large corpora of texts. After presenting\n",
    "guidelines for choosing an appropriate approach in\n",
    "<a href=\"#sec-deciding\" class=\"quarto-xref\">Section 2.6</a> and\n",
    "downloading an example dataset in\n",
    "<a href=\"#sec-reviewdataset\" class=\"quarto-xref\">Section 2.7</a>, we\n",
    "discuss multiple techniques in detail. We begin with a very simple\n",
    "top-down approach in\n",
    "<a href=\"#sec-dictionary\" class=\"quarto-xref\">Section 2.10</a>, in which\n",
    "we count occurrences of words from an *a priori* defined list of words.\n",
    "In <a href=\"#sec-supervised\" class=\"quarto-xref\">Section 2.14</a>, we\n",
    "still use pre-defined categories that we want to code, but let the\n",
    "machine “learn” the rules of the coding itself. Finally, in\n",
    "<a href=\"#sec-unsupervised\" class=\"quarto-xref\">Section 2.24</a>, we\n",
    "employ a bottom-up approach in which we do not use any *a priori*\n",
    "defined lists or coding schemes, but inductively extract topics from our\n",
    "data.\n",
    "\n",
    "## Deciding on the Right Method\n",
    "\n",
    "When thinking about the computational analysis of texts, it is important\n",
    "to realize that there is no method that is *the one* to do so. While\n",
    "there are good choices and bad choices, we also cannot say that one\n",
    "method is necessarily and always superior to another. Some methods are\n",
    "more fashionable than others. For instance, there has been a growing\n",
    "interest in topic models (see\n",
    "<a href=\"#sec-unsupervised\" class=\"quarto-xref\">Section 2.24</a>) in the\n",
    "past few years. There are indeed very good applications for such models,\n",
    "they are also sometimes applied to research questions and/or data where\n",
    "they make much less sense. As always, the choice of method should follow\n",
    "the research question and not the other way round. We therefore caution\n",
    "you about reading\n",
    "<a href=\"#sec-chap-text\" class=\"quarto-xref\">Section 1</a> selectively\n",
    "because you want, for instance, to learn about supervised machine\n",
    "learning or about unsupervised topic models. Instead, you should be\n",
    "aware of very different approaches to make an informed decision on what\n",
    "to use when.\n",
    "\n",
    "@Boumans2016 provide useful guidelines for this. They place automatic\n",
    "text analysis approaches on a continuum from deductive (or top-down) to\n",
    "inductive (or bottom-up). At the deductive end of the spectrum, they\n",
    "place dictionary approaches\n",
    "(<a href=\"#sec-dictionary\" class=\"quarto-xref\">Section 2.10</a>). Here,\n",
    "the researcher has strong *a priori* (theoretical) assumptions (for\n",
    "instance, which topics exist in a news data set; or which words are\n",
    "positive or negative) and can compile lists of words or rules based on\n",
    "these assumptions. The computer then only needs to execute these rules.\n",
    "At the inductive end of the spectrum, in contrast, lie approaches such\n",
    "as topic models\n",
    "(<a href=\"#sec-unsupervised\" class=\"quarto-xref\">Section 2.24</a>) where\n",
    "little or no *a priori* assumptions are made, and where we exploratively\n",
    "look for patterns in the data. Here, we typically do not know which\n",
    "topics exist in advance. Supervised approaches\n",
    "(<a href=\"#sec-supervised\" class=\"quarto-xref\">Section 2.14</a>) can be\n",
    "placed in between: here, we do define categories *a priori* (we do know\n",
    "which topics exist, and given an article, we know to which topic it\n",
    "belongs), but we do not have any set of rules: we do not know which\n",
    "words to look for or which exact rules to follow. These rules are to be\n",
    "“learned” by the computer from the data.\n",
    "\n",
    "Before we get into the details and implementations, let us discuss some\n",
    "use cases of the three main approaches for the computational analysis of\n",
    "text: dictionary (or rule-based) approaches, supervised machine\n",
    "learning, and unsupervised machine learning.\n",
    "\n",
    "Dictionary approaches excel under three conditions. First, the variable\n",
    "we want to code is *manifest and concrete* rather than *latent and\n",
    "abstract*: names of actors, specific physical objects, specific phrases,\n",
    "etc., rather than feelings, frames, or topics. Second, all synonyms to\n",
    "be included must be known beforehand. And third, the dictionary entries\n",
    "must not have multiple meanings. For instance, coding for how often gun\n",
    "control is mentioned in political speeches fits these criteria. There\n",
    "are only so many ways to talk about it, and it is rather unlikely that\n",
    "speeches about other topics contain a phrase like “gun control”.\n",
    "Similarly, if we want to find references to Angela Merkel, Donald Trump,\n",
    "or any other well-known politician, we can just directly search for\n",
    "their names – even though problems arise when people have very common\n",
    "surnames and are referred to by their surnames only.\n",
    "\n",
    "Sadly, most interesting concepts are more complex to code. Take a\n",
    "seemingly straightforward problem: distinguishing whether a news article\n",
    "is about the economy or not. This is really easy to do for humans: there\n",
    "may be some edge cases, but in general, people rarely need longer than a\n",
    "few seconds to grasp whether an article is about the economy rather than\n",
    "about sports, culture, etc. Yet, many of these articles won’t directly\n",
    "state that they are about the economy by explicitly using the word\n",
    "“economy”.\n",
    "\n",
    "We may think of extending our dictionary not only with `econom.+` (a\n",
    "regular expression that includes economists, economic, and so on), but\n",
    "also come up with other words like “stock exchange”, “market”,\n",
    "“company.” Unfortunately, we will quickly run into a problem that we\n",
    "also faced when we discussed the precision-recall trade-off in\n",
    "**?@sec-validation**: the more terms we add to our dictionary, the more\n",
    "false positives we will get: articles about the geographical space\n",
    "called “market”, about some celebrity being seen in “company” of someone\n",
    "else, and so on.\n",
    "\n",
    "From this example, we can conclude that often (1) it is easy for humans\n",
    "to decide to which class a text belongs, but (2) it is very hard for\n",
    "humans to come up with a list of words (or rules) on which their\n",
    "judgment is based. Such a situation is perfect for applying supervised\n",
    "machine learning: after all, it won’t take us much time to annotate,\n",
    "say, 1000 articles based on whether they are about the economy or not\n",
    "(probably this takes less time than thoroughly fine tuning a list of\n",
    "words to include or exclude); and the difficult part, deciding on the\n",
    "exact rules underlying the decision to classify an article as economic\n",
    "is done by the computer in seconds. Supervised machine learning,\n",
    "therefore, has replaced dictionary approaches in many areas.\n",
    "\n",
    "Both dictionary (or rule-based) approaches and supervised machine\n",
    "learning assume that you know in advance which categories (positive\n",
    "versus negative; sports versus economy versus politics; …) exist. The\n",
    "big strength of unsupervised approaches such as topic models is that you\n",
    "can also apply them without this knowledge. They therefore allow you to\n",
    "find patterns in data that you did not expect and can generate new\n",
    "insights. This makes them particularly suitable for explorative research\n",
    "questions. Using them for confirmatory tests, in contrast, is less\n",
    "defensible: after all, if we are interested in knowing whether, say,\n",
    "news site A published more about the economy than news site B, then it\n",
    "would be a bit weird to pretend not to know that the topic “economy”\n",
    "exists. Also practically, mapping the resulting topics that the topic\n",
    "model produces onto such *a priori* existing categories can be\n",
    "challenging.\n",
    "\n",
    "Despite all differences, all approaches share one requirement: you need\n",
    "to “Validate. Validate. Validate” \\[@Grimmer2013\\]. Though it has been\n",
    "done in the past, simply applying a dictionary without comparing the\n",
    "performance to manual coding of the same concepts is not acceptable;\n",
    "neither is using a supervised machine learning classifier without doing\n",
    "the same; or blindly trusting a topic model without at least manually\n",
    "checking whether the scores the model assigns to documents really\n",
    "capture what the documents are about.\n",
    "\n",
    "## Obtaining a Review Dataset\n",
    "\n",
    "For the sections on dictionary and supervised approaches we will use a\n",
    "dataset of movie reviews from the IMDB database \\[@aclimdb\\]. This\n",
    "dataset is published as a compressed set of folders, with separate\n",
    "folders for the train and test datasets and subfolders for positive and\n",
    "negative reviews. Lots of other review datasets are available online,\n",
    "for example for Amazon review data\n",
    "([jmcauley.ucsd.edu/data/amazon/](https://jmcauley.ucsd.edu/data/amazon/)).\n",
    "\n",
    "The IMDB dataset we will use is a relatively large file and it requires\n",
    "bit of processing, so it is smart to *cache* the data rather than\n",
    "downloading and processing it every time you need it. This is done in\n",
    "**?@exm-reviewdata**, which also serves as a nice example of how to\n",
    "download and process files. Both R and Python follow the same basic\n",
    "pattern. First, we check whether the cached file exists, and if it does\n",
    "we read the data from that file. For R, we use the standard *RDS*\n",
    "format, while for Python we use a compressed *pickle* file. The format\n",
    "of the data is also slightly different, following the convention for\n",
    "each language: In R we use the data frame returned by `readtext`, which\n",
    "can read files from a folder or zip archive and return a data frame\n",
    "containing one text per row. In Python, we have separate lists for the\n",
    "train and test datasets and for the full texts and labels: `text_train`\n",
    "are the training texts and `y_train` are the corresponding labels.\n",
    "\n",
    "Downloading and caching IMDB review data.\n",
    "\n",
    "## Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13352565-1e15-435b-a13d-05f48f6c05e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached file reviewdata.pickle.bz2\n"
     ]
    }
   ],
   "source": [
    "filename = \"reviewdata.pickle.bz2\"\n",
    "if os.path.exists(filename):\n",
    "    print(f\"Using cached file {filename}\")\n",
    "    with bz2.BZ2File(filename, \"r\") as zipfile:\n",
    "        data = pickle.load(zipfile)\n",
    "    text_train, text_test, y_train, y_test = data\n",
    "else:\n",
    "    url = \"https://cssbook.net/d/aclImdb_v1.tar.gz\"\n",
    "    print(f\"Downloading from {url}\")\n",
    "    fn, _headers = urllib.request.urlretrieve(url, filename=None)\n",
    "    t = tarfile.open(fn, mode=\"r:gz\")\n",
    "    text_train, text_test = [], []\n",
    "    y_train, y_test = [], []\n",
    "    for f in t.getmembers():\n",
    "        m = re.match(\"aclImdb/(\\w+)/(pos|neg)/\", f.name)\n",
    "        if not m:\n",
    "            # skip folder names, other categories\n",
    "            continue\n",
    "        dataset, label = m.groups()\n",
    "        text = t.extractfile(f).read().decode(\"utf-8\")\n",
    "        if dataset == \"train\":\n",
    "            text_train.append(text)\n",
    "            y_train.append(label)\n",
    "        elif dataset == \"test\":\n",
    "            text_test.append(text)\n",
    "            y_test.append(label)\n",
    "    data = text_train, text_test, y_train, y_test\n",
    "    print(f\"Saving to {filename}\")\n",
    "    with bz2.BZ2File(filename, \"w\") as zipfile:\n",
    "        pickle.dump(data, zipfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729b169-f73f-437a-ba55-343cde563891",
   "metadata": {},
   "source": [
    "If the cached data file does not exist yet, the file is downloaded from\n",
    "the Internet. In R, we then extract the file and call `readtext` on the\n",
    "resulting folder. This automatically creates columns for the subfolders,\n",
    "so in this case for the dataset and label. After this, we remove the\n",
    "download file and the extracted folder, clean up the `reviewdata`, and\n",
    "save it to the `reviewdata.rds` file. In Python, we can extract files\n",
    "from the downloaded file directly, so we do not need to explicitly\n",
    "extract it. We loop over all files in the archive, and use a regular\n",
    "expression to select only text files and extract the label and dataset\n",
    "name (see **?@sec-regular** for more information about regular\n",
    "expressions). Then, we extract the text from the archive, and add the\n",
    "text and the label to the appropriate list. Finally, the data is saved\n",
    "as a compressed pickle file, so the next time we run this cell it does\n",
    "not need to download the file again.\n",
    "\n",
    "## Dictionary Approaches to Text Analysis\n",
    "\n",
    "A straightforward way to automatically analyze text is to compile a list\n",
    "of terms you are interested in and simply count how often they occur in\n",
    "each document. For example, if you are interested in finding out whether\n",
    "mentions of political parties in news articles change over the years,\n",
    "you only need to compile a list of all party names and write a small\n",
    "script to count them.\n",
    "\n",
    "Historically, this is how sentiment analysis was done. Example\n",
    "**?@exm-sentsimple** shows how to do a simple sentiment analysis based\n",
    "on a list of positive and negative words. The logic is straightforward:\n",
    "you count how often each positive word occurs in a text, you do the same\n",
    "for the negative words, and then determine which occur more often.\n",
    "\n",
    "Different approaches to a simple dictionary-based sentiment analysis:\n",
    "counting and summing all words using a for-loop over all reviews\n",
    "(Python) versus constructing a term-document matrix and looking up the\n",
    "words in there (R). Note that both approaches would be possible in\n",
    "either language.\n",
    "\n",
    "## Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7f7edb8-dbae-40d7-b3f3-8ae28b65c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3, -4, 1, 3, -2, -7, -6, 9, 7, 7, 10, 5, -1, 2, 7, -4, 2, 21, 1, -1, 2, -3, -2, -11, -2, -3, -7, 2, 4, -22, 5, 4, 3, -5, -8, 1, -1, 0, 1, 8, 0, -4, 3, -7, -11, -6, 0, 3, -1, 0, 6, -1, -8, 7, -5, 2, 10, 5, 5, 1, 0, 7, 0, 0, 5, 1, -8, 4, 3, 18, 2, 0, -3, -2, 5, 0, -2, 1, 1, 12, -3, -4, -6, -2, 2, -7, -1, -10, -5, 3, 4, -3, -17, 1, -1, 7, -3, 4, 12, 3]\n"
     ]
    }
   ],
   "source": [
    "poswords = \"https://cssbook.net/d/positive.txt\"\n",
    "negwords = \"https://cssbook.net/d/negative.txt\"\n",
    "pos = set(requests.get(poswords).text.split(\"\\n\"))\n",
    "neg = set(requests.get(negwords).text.split(\"\\n\"))\n",
    "sentimentdict = {word: +1 for word in pos}\n",
    "sentimentdict.update({word: -1 for word in neg})\n",
    "\n",
    "scores = []\n",
    "mytokenizer = TreebankWordTokenizer()\n",
    "# For speed, we only take the first 100 reviews\n",
    "for review in text_train[:100]:\n",
    "    words = mytokenizer.tokenize(review)\n",
    "    # we look up each word in the sentiment dict\n",
    "    # and assign its value (with default 0)\n",
    "    scores.append(sum(sentimentdict.get(word, 0) for word in words))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c567a-1401-4ddb-9b82-3a102384ded5",
   "metadata": {},
   "source": [
    "As you may already realize, there are a lot of downsides to this\n",
    "approach. Most notably, our bag-of-words approach does not allow us to\n",
    "account for negation: “not good” will be counted as positive. Relatedly,\n",
    "we cannot handle modifiers such as “very good”. Also, all words are\n",
    "either positive or negative, while “great” should be more positive than\n",
    "“good”. More advanced dictionary-based sentiment analysis packages like\n",
    "Vader \\[@Hutto2014\\] or SentiStrength \\[@Thelwall2012\\] include such\n",
    "functionalities. Yet, as we will discuss in Section\n",
    "<a href=\"#sec-supervised\" class=\"quarto-xref\">2.14</a>, also these\n",
    "off-the-shelf packages perform very poorly in many sentiment analysis\n",
    "tasks, especially outside of the domains they were developed for.\n",
    "Dictionary-based sentiment analysis has been shown to be problematic\n",
    "when analyzing news content (e.g. @Gonzalez-Bailon2015; @Boukes2019).\n",
    "They are problematic when accuracy at the sentence level is important,\n",
    "but may be satisfactory with longer texts for comparatively easy tasks\n",
    "such as movie review classification \\[@Reagan2017\\], where there is\n",
    "clear ground truth data and the genre convention implies that the whole\n",
    "text is evaluative and evaluates one object (the film).\n",
    "\n",
    "Still, there are many use cases where dictionary approaches work very\n",
    "well. Because your list of words can contain anything, not just positive\n",
    "or negative words, dictionary approaches have been used, for instance,\n",
    "to measure the use of racist words or swearwords in online fora \\[e.g.,\n",
    "@Tulkens2016\\]. Dictionary approaches are simple to understand and\n",
    "straightforward, which can be a good argument for using them when it is\n",
    "important that the method is no black-box but fully transparent even\n",
    "without technical knowledge. Especially when the dictionary already\n",
    "exists or is easy to create, it is also a very cheap method. However,\n",
    "this is at the expense of their limitation to only performing well when\n",
    "measuring easy to operationalize concepts. To put it bluntly: it’s great\n",
    "for measuring the visibility of parties or organizations in the news,\n",
    "but it’s not good for measuring concepts such as emotions or frames.\n",
    "\n",
    "What gave dictionary approaches a bit of a bad name is that many\n",
    "researchers applied them without validating them. This is especially\n",
    "problematic when a dictionary is applied in a slightly different domain\n",
    "than that for which it was originally made.\n",
    "\n",
    "If you want to use a dictionary-based approach, we advise the following\n",
    "procedure:\n",
    "\n",
    "-   Construct a dictionary based on theoretical considerations and by\n",
    "    closely reading a sample of example texts.\n",
    "    -   Code some articles manually and compare with the automated\n",
    "        coding.\n",
    "    -   Improve your dictionary and check again.\n",
    "    -   Manually code a validation dataset of sufficient size. The\n",
    "        required size depends a bit on how balanced your data is – if\n",
    "        one code occurs very infrequently, you will need more data.\n",
    "    -   Calculate the agreement. You could use standard intercoder\n",
    "        reliability measures used in manual content analysis, but we\n",
    "        would also advise you to calculate precision and recall (see\n",
    "        Section **?@sec-validation**).\n",
    "\n",
    "Very extensive dictionaries will have a high recall (it becomes\n",
    "increasingly unlikely that you “miss” a relevant document), but often\n",
    "suffer from low precision (more documents will contain one of the words\n",
    "even though they are irrelevant). Vice versa, a very short dictionary\n",
    "will often be very precise, but miss a lot of documents. It depends on\n",
    "your research question where the right balance lies, but to\n",
    "substantially interpret your results, you need to be able to quantify\n",
    "the performance of your dictionary-based approach.\n",
    "\n",
    "## How many documents do you need to calculate agreement with human annotators?\n",
    "\n",
    "To determine the number of documents one needs to determine the\n",
    "agreement between a human and a machine, one can follow the same\n",
    "standards that are recommended for traditional manual content analysis.\n",
    "\n",
    "For instance, @Krippendorff2004 provides a convenience table to look up\n",
    "the required sample sizes for determining the agreement between two\n",
    "human coders (p. 240). @Riffe2019 provide similar suggestions (p. 114).\n",
    "In short, the sample size depends on the level of statistical\n",
    "significance the researcher deems acceptable as well as on the\n",
    "distribution of the data. In an extreme case, if only 5 out of 100 items\n",
    "are to be coded as $x$, then in a sample of 20 items, such an item may\n",
    "not even occur. In order to determine agreement between the automated\n",
    "method and a human, we suggest that sample sizes that one would also use\n",
    "for the calculation of agreement between human coders are used. For\n",
    "specific calculations, we refer to content analysis books such as the\n",
    "two referenced here. To give a very rough ballpark figure (that\n",
    "shouldn’t replace a careful calculation!), roughly 100 to 200 items will\n",
    "cover many scenarios (assuming a small amount of reasonably balanced\n",
    "classes).\n",
    "\n",
    "## Supervised Text Analysis: Automatic Classification and Sentiment Analysis\n",
    "\n",
    "For many applications, there are good reasons to use the dictionary\n",
    "approach presented in the previous section. First, it is intuitively\n",
    "understandable and results can – in principle – even be verified by\n",
    "hand, which can be an advantage when transparency or communicability is\n",
    "of high importance. Second, it is very easy to use. But as we have\n",
    "discussed in\n",
    "<a href=\"#sec-deciding\" class=\"quarto-xref\">Section 2.6</a>, dictionary\n",
    "approaches in general perform less well the more abstract, non-manifest,\n",
    "or complex a concept becomes. In the next section, we will make the case\n",
    "that topics, but also sentiment, in fact, are quite a complex concepts\n",
    "that are often hard to capture with dictionaries (or at least, crafting\n",
    "a custom dictionary would be difficult). For instance, while “positive”\n",
    "and “negative” seem straightforward categories at first sight, the more\n",
    "we think about it, the more apparent it becomes how context-dependent it\n",
    "actually is: in a dataset about the economy and stock market returns,\n",
    "“increasing” may indicate something positive, in a dataset about\n",
    "unemployment rates the same word would be something negative. Thus,\n",
    "machine learning can be a more appropriate technique for such tasks.\n",
    "\n",
    "### Putting Together a Workflow\n",
    "\n",
    "With the knowledge we gained in previous chapters, it is not difficult\n",
    "to set up a supervised machine learning classifier to automatically\n",
    "determine, for instance, the topic of a news article.\n",
    "\n",
    "Let us recap the building blocks that we need. In\n",
    "**?@sec-chap-introsml**, you learned how to use different classifiers,\n",
    "how to evaluate them, and how to choose the best settings. However, in\n",
    "these examples, we used numerical data as features; now, we have text.\n",
    "In **?@sec-chap-dtm**, you learned how to turn text into numerical\n",
    "features. And that’s all we need to get started!\n",
    "\n",
    "Typical examples for supervised machine learning in the analysis of\n",
    "communication include the classification of topics \\[e.g.,\n",
    "@Scharkow2011\\], frames \\[e.g., @Burscher2014\\], user characteristics\n",
    "such as gender or ideology, or sentiment.\n",
    "\n",
    "Let us consider the case of sentiment analysis in more detail. Classical\n",
    "sentiment analysis is done with a dictionary approach: you take a list\n",
    "of positive words, a list of negative words, and count which occur more\n",
    "frequently. Additionally, one may attach a weight to each word, such\n",
    "that “perfect” gets a higher weight than “good”, for instance. An\n",
    "obvious drawback is that these pure bag-of-words approaches cannot cope\n",
    "with negation (“not good”) and intensifiers (“very good”), which is why\n",
    "extensions have been developed that take these (and other features, such\n",
    "as punctuation) into account \\[@Thelwall2012; @Hutto2014;\n",
    "@DeSmedt2012\\].\n",
    "\n",
    "But while available off-the-shelf packages that implement these extended\n",
    "dictionary-based methods are very easy to use (in fact, they spit out a\n",
    "sentiment score with one single line of code), it is questionable how\n",
    "well they work in practice. After all, “sentiment” is not exactly a\n",
    "clear, manifest concept for which we can enumerate a list of words. It\n",
    "has been shown that results obtained with multiple of these packages\n",
    "correlate very poorly with each other and with human annotations\n",
    "\\[@Boukes2019; @Chan2021\\].\n",
    "\n",
    "Consequently, it has been suggested that it is better to use supervised\n",
    "machine learning to automatically code the sentiment of texts\n",
    "\\[@Gonzalez-Bailon2015; @vermeer2019seeing\\]. However, you may need to\n",
    "annotate documents from your own dataset: training a classifier on, for\n",
    "instance, movie reviews and then using it to predict sentiment in\n",
    "political texts violates the assumption that training set, test set, and\n",
    "the unlabeled data that are to be classified are (at least in principle\n",
    "and approximately) drawn from the same population.\n",
    "\n",
    "To illustrate the workflow, we will use the ACL IMDB dataset, a large\n",
    "dataset that consists of a training dataset of 25000 movie reviews (of\n",
    "which 12500 are positive and 12500 are negative) and an equally sized\n",
    "test dataset \\[@aclimdb\\]. It can be downloaded at\n",
    "[ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)\n",
    "\n",
    "These data do not come in one file, but rather in a set of text files\n",
    "that are sorted in different folders named after the dataset to which\n",
    "they belong (`test` or `train`) and their label (`pos` and `neg`). This\n",
    "means that we cannot simply use a pre-defined function to read them, but\n",
    "we need to think of a way of reading the content into a data structure\n",
    "that we can use. This data was loaded in **?@exm-reviewdata** above.\n",
    "\n",
    "## Sparse versus dense matrices in Python and R\n",
    "\n",
    "In a document-term matrix, you would typically find a lot of zeros: most\n",
    "words do *not* appear in any given document. For instance, the reviews\n",
    "in the IMDB dataset contain more than 100000 unique words. Hence, the\n",
    "matrix has more than 100000 columns. Yet, most reviews only consist of a\n",
    "couple of hundred words. As a consequence, more than 99% of the cells in\n",
    "the table contain a zero. In a sparse matrix, we do not store all these\n",
    "zeros, but only store the values for cells that actually contain a\n",
    "value. This drastically reduces the memory needed. But even if you have\n",
    "a huge amount of memory, this does not solve the issue: in R, the number\n",
    "of cells in a matrix is limited to 2147483647. It is therefore\n",
    "impossible to store a matrix with 100000 features and 25000 documents as\n",
    "a dense matrix. Unfortunately, many models that you can run via *caret*\n",
    "in R will convert your sparse document-term matrix to a dense matrix,\n",
    "and hence are effectively only usable for very small datasets. An\n",
    "alternative is using the *quanteda* package, which does use sparse\n",
    "matrices throughout. However, at the time of writing this book, quanteda\n",
    "only provides a very limited number of models. As all of these problems\n",
    "do not arise in *scikit-learn*, you may want to consider using Python\n",
    "for many text classification tasks.\n",
    "\n",
    "Let us now train our first classifier. We choose a Naïve Bayes\n",
    "classifier with a simple count vectorizer (**?@exm-imdbbaseline**). In\n",
    "the Python example, pay attention to the fitting of the vectorizer: we\n",
    "fit on the training data *and* transform the training data with it, but\n",
    "we only transform the test data *without re-fitting the vectorizer*.\n",
    "Fitting, here, includes the decision about which words to include (by\n",
    "definition, words that are not present in the training data are not\n",
    "included; but we could also choose additional constraints, such as\n",
    "excluding very rare or very common words), but also assigning an\n",
    "(internally used) identifier (variable name) to each word. If we fit the\n",
    "classifier again, these would not be compatible any more. In R, the same\n",
    "is achieved in a slightly different way: two term-document matrices are\n",
    "created independently, before they are matched in such a way that only\n",
    "the features that are present in the training matrix are retained in the\n",
    "test matrix.\n",
    "\n",
    "A word that is not present in the training data, but is present in the\n",
    "test data, is thus ignored. If you want to use the information such\n",
    "out-of-vocabulary words can entail (e.g., they may be synonyms),\n",
    "consider using a word embedding approach (see **?@sec-wordembeddings**)\n",
    "\n",
    "We do not necessarily expect this first model to be the best classifier\n",
    "we can come up with, but it provides us with a reasonable baseline. In\n",
    "fact, even without any further adjustments, it works reasonably well:\n",
    "precision is higher for positive reviews and recall is higher for\n",
    "negative reviews (classifying a positive review as negative happens\n",
    "twice as much as the reverse), but none of the values is concerningly\n",
    "low.\n",
    "\n",
    "Training a Naïve Bayes classifier with simple word counts as features\n",
    "\n",
    "## Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d6f6e0e-355c-43f8-96f8-ef26db81cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.88      0.83     12500\n",
      "         pos       0.86      0.76      0.81     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.82      0.82      0.82     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(text_train)\n",
    "X_test = vectorizer.transform(text_test)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "rep = metrics.classification_report(y_test, y_pred)\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417b4d6-64e4-4f5e-a8f4-e90ba63a4ad2",
   "metadata": {},
   "source": [
    "### Finding the Best Classifier\n",
    "\n",
    "Let us start by comparing the two simple classifiers we know (Naïve\n",
    "Bayes and Logistic Regression (see **?@sec-nb2dnn**) and the two\n",
    "vectorizers that transform our texts into two numerical representations\n",
    "that we know: word counts and `tf.idf` scores (see **?@sec-chap-dtm**).\n",
    "\n",
    "We can also tune some things in the vectorizer, such as filtering out\n",
    "stopwords, or specifying a minimum number (or proportion) of documents\n",
    "in which a word needs to occur in order to be included, or the maximum\n",
    "number (or proportion) of documents in which it is allowed to occur. For\n",
    "instance, it could make sense to say that a word that occurs in less\n",
    "than $n=5$ documents is probably a spelling mistake or so unusual that\n",
    "it just unnecessarily bloats our feature matrix; and on the other hand,\n",
    "a word that is so common that it occurs in more than 50% of all\n",
    "documents is so common that it does not help us to distinguish between\n",
    "different classes.\n",
    "\n",
    "We can try all of these things out by hand by just re-running the code\n",
    "from **?@exm-imdbbaseline** and only changing the line in which the\n",
    "vectorizer is specified and the line in which the classifier is\n",
    "specified. However, copy-pasting essentially the same code is generally\n",
    "not a good idea, as it makes your code unnecessary long and increases\n",
    "the likelihood of errors creeping in when you, for instance, need to\n",
    "apply the same changes to multiple copies of the code. A more elegant\n",
    "approach is outlined in **?@exm-basiccomparisons**: We define a function\n",
    "that gives us a short summary of only the output we are interested in,\n",
    "and then use a for-loop to iterate over all configurations we want to\n",
    "evaluate, fit them and call the function we defined before. In fact,\n",
    "with 23 lines of code, we manage to compare four different models, while\n",
    "we already needed 15 lines (in **?@exm-imdbbaseline**) to evaluate only\n",
    "one model.\n",
    "\n",
    "An example of a custom function to give a brief overview of the\n",
    "performance of four simple vectorizer-classifier combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f13e8bd-0b1d-4895-ac17-5b3b44f7476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_classification_report(y_test, y_pred):\n",
    "    print(\"    \\tPrecision\\tRecall\")\n",
    "    for label in set(y_pred):\n",
    "        pr = metrics.precision_score(y_test, y_pred, pos_label=label)\n",
    "        re = metrics.recall_score(y_test, y_pred, pos_label=label)\n",
    "        print(f\"{label}:\\t{pr:0.2f}\\t\\t{re:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87f3561-d4f0-4dcf-9f6e-4de57e6d2187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB-count\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.87\t\t0.77\n",
      "neg:\t0.79\t\t0.88\n",
      "\n",
      "\n",
      "NB-TfIdf\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.87\t\t0.78\n",
      "neg:\t0.80\t\t0.88\n",
      "\n",
      "\n",
      "LR-Count\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.87\t\t0.85\n",
      "neg:\t0.85\t\t0.87\n",
      "\n",
      "\n",
      "LR-TfIdf\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.89\t\t0.88\n",
      "neg:\t0.88\t\t0.89\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    (\"NB-count\", CountVectorizer(min_df=5, max_df=0.5), MultinomialNB()),\n",
    "    (\"NB-TfIdf\", TfidfVectorizer(min_df=5, max_df=0.5), MultinomialNB()),\n",
    "    (\n",
    "        \"LR-Count\",\n",
    "        CountVectorizer(min_df=5, max_df=0.5),\n",
    "        LogisticRegression(solver=\"liblinear\"),\n",
    "    ),\n",
    "    (\n",
    "        \"LR-TfIdf\",\n",
    "        TfidfVectorizer(min_df=5, max_df=0.5),\n",
    "        LogisticRegression(solver=\"liblinear\"),\n",
    "    ),\n",
    "]\n",
    "\n",
    "for name, vectorizer, classifier in configs:\n",
    "    print(name)\n",
    "    X_train = vectorizer.fit_transform(text_train)\n",
    "    X_test = vectorizer.transform(text_test)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    short_classification_report(y_test, y_pred)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88311f-86a6-45ef-83fe-a5169e6884b1",
   "metadata": {},
   "source": [
    "The output of this little example already gives us quite a bit of\n",
    "insight into how to tackle our specific classification tasks: first, we\n",
    "see that a $tf\\cdot idf$ classifier seems to be slightly but\n",
    "consistently superior to a count classifier (this is often, but not\n",
    "always the case). Second, we see that the logistic regression performs\n",
    "better than the Naïve Bayes classifier (again, this is often, but not\n",
    "always, the case). In particular, in our case, the logistic regression\n",
    "improved on the excessive misclassification of positive reviews as\n",
    "negative, and achieves a very balanced performance.\n",
    "\n",
    "There may be instances where one nevertheless may want to use a Count\n",
    "Vectorizer with a Naïve Bayes classifier instead (especially if it is\n",
    "too computationally expensive to estimate the other model), but for now,\n",
    "we may settle on the best performing combination, logistic regression\n",
    "with a `tf.idf` vectorizer. You could also try fitting a Support Vector\n",
    "Machine instead, but we have little reason to believe that our data\n",
    "isn’t linearly separable, which means that there is little reason to\n",
    "believe that the SVM will perform better. Given the good performance we\n",
    "already achieved, we decide to stick to the logistic regression for now.\n",
    "\n",
    "We can now go as far as we like, include more models, use\n",
    "crossvalidation and gridsearch (see **?@sec-crossvalidation**), etc.\n",
    "However, our workflow now consists of *two* steps: fitting/transforming\n",
    "our input data using a vectorizer, and fitting a classifier. To make\n",
    "things easier, in scikit-learn, both steps can be combined into a\n",
    "so-called pipe. **?@exm-basicpipe** shows how the loop in\n",
    "**?@exm-basiccomparisons** can be re-written using pipes (the result\n",
    "stays the same).\n",
    "\n",
    "Instead of fitting vectorizer and classifier separately, they can be\n",
    "combined in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08297cc2-36a1-4d9a-b160-a309d83085dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB-count\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.87\t\t0.77\n",
      "neg:\t0.79\t\t0.88\n",
      "\n",
      "\n",
      "NB-TfIdf\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.87\t\t0.78\n",
      "neg:\t0.80\t\t0.88\n",
      "\n",
      "\n",
      "LR-Count\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.87\t\t0.85\n",
      "neg:\t0.85\t\t0.87\n",
      "\n",
      "\n",
      "LR-TfIdf\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.89\t\t0.88\n",
      "neg:\t0.88\t\t0.89\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, vectorizer, classifier in configs:\n",
    "    print(name)\n",
    "    pipe = make_pipeline(vectorizer, classifier)\n",
    "    pipe.fit(text_train, y_train)\n",
    "    y_pred = pipe.predict(text_test)\n",
    "    short_classification_report(y_test, y_pred)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904eec4-4f1b-4c97-af5b-ba7a9dc47ab2",
   "metadata": {},
   "source": [
    "Such a pipeline lends itself very well to performing a gridsearch.\n",
    "**?@exm-gridsearchlogreg** gives you an example. With\n",
    "`LogisticRegression?` and `TfIdfVectorizer?`, we can get a list of all\n",
    "possible hyperparameters that we may want to tune. For instance, these\n",
    "could be the minimum and maximum frequency for words to be included or\n",
    "whether we want to use only unigrams (single words) or also bigrams\n",
    "(combinations of two words, see **?@sec-ngram**). For the Logistic\n",
    "Regression, it may be the regularization hyperparameter C, which applies\n",
    "a penalty for too complex models. We can put all values for these\n",
    "parameters that we want to consider in a dictionary, with a descriptive\n",
    "key (i.e., a string with the step of the pipeline followed by two\n",
    "underscores and the name of the hyperparameter) and a list of all values\n",
    "we want to consider as the corresponding value.\n",
    "\n",
    "The gridsearch procedure will then estimate all combinations of all\n",
    "values, using cross-validation (see **?@sec-validation**). In our\n",
    "example, we have $2 x 2 x 2 x 2 x 3 = 24$ different models, and\n",
    "$24 models x 5 folds = 120$ models to estimate. Hence, it may take you\n",
    "some time to run the code.\n",
    "\n",
    "A gridsearch to find the best hyperparameters for a pipeline consisting\n",
    "of a vectorizer and a classifier. Note that we can tune any parameter\n",
    "that either the vectorizer or the classifier accepts as an input, not\n",
    "only the four hyperparameters we chose in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e061b8ed-d85b-4016-8ee1-aa98c63fdb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damian/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 472, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 409, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1329, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\", line 2093, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/damian/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/damian/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1052: UserWarning: One or more of the test scores are non-finite: [    nan     nan 0.80964 0.82356     nan     nan 0.784   0.7942      nan\n",
      "     nan 0.86436 0.87752     nan     nan 0.8652  0.8758      nan     nan\n",
      " 0.8298  0.87588     nan     nan 0.83428 0.87552]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 1, 'vectorizer__max_df': 0.5, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}\n",
      "    \tPrecision\tRecall\n",
      "pos:\t0.89\t\t0.90\n",
      "neg:\t0.90\t\t0.89\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"vectorizer\", TfidfVectorizer()),\n",
    "        (\"classifier\", LogisticRegression(solver=\"liblinear\")),\n",
    "    ]\n",
    ")\n",
    "grid = {\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"vectorizer__max_df\": [0.5, 1.0],\n",
    "    \"vectorizer__min_df\": [0, 5],\n",
    "    \"classifier__C\": [0.01, 1, 100],\n",
    "}\n",
    "search = GridSearchCV(\n",
    "    estimator=pipeline, n_jobs=-1, param_grid=grid, scoring=\"accuracy\", cv=5\n",
    ")\n",
    "search.fit(text_train, y_train)\n",
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "pred = search.predict(text_test)\n",
    "print(short_classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8d0d0-f85d-4201-b51d-5a084412accb",
   "metadata": {},
   "source": [
    "We see that we could further improve our model to precision and recall\n",
    "values of 0.90, by excluding extremely infrequent and extremely frequent\n",
    "words, including both unigrams and bigrams (which, we may speculate,\n",
    "help us to account for the “not good” versus “not”, “good” problem), and\n",
    "changing the default penalty of $C=1$ to $C=100$.\n",
    "\n",
    "Let us, just for the sake of it, compare the performance of our model\n",
    "with an off-the-shelf sentiment analysis package, in this case Vader\n",
    "\\[@Hutto2014\\]. For any text, it will directly estimate sentiment scores\n",
    "(more specifically, a positivity score, a negativity score, a neutrality\n",
    "score, and a compound measure that combines them), without any need to\n",
    "have training data. However, as Example **?@exm-vader** shows, such a\n",
    "method is clearly inferior to a supervised machine learning approach.\n",
    "While in almost all cases (except for $n=11$ cases), Vader was able to\n",
    "make a choice (getting scores of 0 is a notorious problem in very short\n",
    "texts), precision and recall are clearly worse than even the simple\n",
    "baseline model we started with, and much worse than those of the final\n",
    "model we finished with. In fact, we miss half (!) of the negative\n",
    "reviews. There are probably very few applications in the analysis of\n",
    "communication in which we would find this acceptable. It is important to\n",
    "highlight that this is not because the off-the-shelf package we chose is\n",
    "a particularly bad one (on the contrary, it is actually comparatively\n",
    "good), but because of the inherent limitations of dictionary-based\n",
    "sentiment analysis.\n",
    "\n",
    "For the sake of comparison, we calculate how an off-the-shelf sentiment\n",
    "analysis package would have performed in this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6560d87e-f068-4173-b3c9-e168a1271deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/damian/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0]\n",
      " [    6  6706  5788]\n",
      " [    5  1748 10747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   dont know       0.00      0.00      0.00         0\n",
      "         neg       0.79      0.54      0.64     12500\n",
      "         pos       0.65      0.86      0.74     12500\n",
      "\n",
      "    accuracy                           0.70     25000\n",
      "   macro avg       0.48      0.47      0.46     25000\n",
      "weighted avg       0.72      0.70      0.69     25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/damian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/damian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "pred = []\n",
    "for review in text_test:\n",
    "    sentiment = analyzer.polarity_scores(review)\n",
    "    if sentiment[\"compound\"] > 0:\n",
    "        pred.append(\"pos\")\n",
    "    elif sentiment[\"compound\"] < 0:\n",
    "        pred.append(\"neg\")\n",
    "    else:\n",
    "        pred.append(\"dont know\")\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c95c478-8e52-45ac-91d8-d3b6cdd24460",
   "metadata": {},
   "source": [
    "We need to keep in mind, though, that with this dataset, we chose one of\n",
    "the easiest sentiment analysis tasks: a set of long, rather formal texts\n",
    "(compared to informal short social media messages), that evaluate\n",
    "exactly one entity (one film), and that are not ambiguous at all. Many\n",
    "applications that communication scientists are interested in are much\n",
    "less straightforward. Therefore, however tempting it may be to use an\n",
    "off-the-shelf package, doing so requires a thorough test based on at\n",
    "least some human-annotated data.\n",
    "\n",
    "### Using the Model\n",
    "\n",
    "So far, we have focused on training and evaluating models, almost\n",
    "forgetting why we were doing this in the first place: to use them to\n",
    "predict the label for new data that we did not annotate.\n",
    "\n",
    "Of course, we could always re-train the model when we need to use it –\n",
    "but that has two downsides: first, as you may have seen, it may actually\n",
    "take considerable time to train it, and second, you need to have the\n",
    "training data available, which may be a problem both in terms of storage\n",
    "space and of copyright and/or privacy if you want to share your\n",
    "classifier with others.\n",
    "\n",
    "Therefore, it makes sense to save both our classifier and our vectorizer\n",
    "to a file, so that we can reload them later (Example **?@exm-reuse**).\n",
    "Keep in mind that you have to re-use *both* – after all, the columns of\n",
    "your feature matrix will be different (and hence, completely useless for\n",
    "the classifier) when fitting a new vectorizer. Therefore, as you see,\n",
    "you do not do any fitting any longer, and only use the `.transform()`\n",
    "method of the (already fitted) vectorizer and the `.predict()` method of\n",
    "the (already fitted) classifier.\n",
    "\n",
    "In R, you have no vectorizer you could save – but because in contrast to\n",
    "Python, both your DTM and your classifier include the feature names, it\n",
    "suffices to save the classifier only (using\n",
    "`saveRDS(myclassifier, \"myclassifier.rds\")`) and using on a new DTM\n",
    "later on. You do need to remember, though, how you constructed the DTM\n",
    "(e.g., which preprocessing steps you took), to make sure that the\n",
    "features are comparable.\n",
    "\n",
    "Saving and loading a vectorizer and a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "757352e8-d6b1-42b4-a919-ae29708923f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This is a great movie' is probably 'pos'.\n",
      "'I hated this one.' is probably 'neg'.\n",
      "'What an awful fail' is probably 'neg'.\n"
     ]
    }
   ],
   "source": [
    "# Make a vectorizer and train a classifier\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.5)\n",
    "classifier = LogisticRegression(solver=\"liblinear\")\n",
    "X_train = vectorizer.fit_transform(text_train)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Save them to disk\n",
    "with open(\"myvectorizer.pkl\", mode=\"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "with open(\"myclassifier.pkl\", mode=\"wb\") as f:\n",
    "    joblib.dump(classifier, f)\n",
    "\n",
    "# Later on, re-load this classifier and apply:\n",
    "new_texts = [\"This is a great movie\", \"I hated this one.\", \"What an awful fail\"]\n",
    "\n",
    "with open(\"myvectorizer.pkl\", mode=\"rb\") as f:\n",
    "    myvectorizer = pickle.load(f)\n",
    "with open(\"myclassifier.pkl\", mode=\"rb\") as f:\n",
    "    myclassifier = joblib.load(f)\n",
    "\n",
    "new_features = myvectorizer.transform(new_texts)\n",
    "pred = myclassifier.predict(new_features)\n",
    "\n",
    "for review, label in zip(new_texts, pred):\n",
    "    print(f\"'{review}' is probably '{label}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add2eac-4292-471a-95e6-000be7f30e69",
   "metadata": {},
   "source": [
    "Another thing that we might want to do is to get a better idea of the\n",
    "features that the model uses to arrive at its prediction; in our\n",
    "example, what actually characterizes the best and the worst reviews.\n",
    "Example **?@exm-eli5** shows how this can be done in one line of code\n",
    "using *eli5* – a package that aims to “*e*xplain \\[the model\\] *l*ike\n",
    "*I*’m *5* years old”. Here, we re-use the `pipe` we constructed earlier\n",
    "to provide both the vectorizer and the classifier to *eli5* – if we had\n",
    "only provided the classifier, then the feature names would have been\n",
    "internal identifiers (which are meaningless to us) rather than\n",
    "human-readable words.\n",
    "\n",
    "Using eli5 to get the most predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f6ac9e-2136-474c-9cb7-f7a25100fc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(max_df=0.5, min_df=5)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(max_df=0.5, min_df=5)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_df=0.5, min_df=5)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(max_df=0.5, min_df=5)),\n",
       "                ('logisticregression', LogisticRegression(solver='liblinear'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    TfidfVectorizer(min_df=5, max_df=0.5),\n",
    "    LogisticRegression(solver=\"liblinear\"),\n",
    ")\n",
    "pipe.fit(text_train, y_train)\n",
    "# print(eli5.format_as_text(eli5.explain_weights(pipe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbad89-784c-4957-a3c2-f5d5615c9f18",
   "metadata": {},
   "source": [
    "We can also use eli5 to explain how the classifier arrived at a\n",
    "prediction for a specific document, by using different shades of green\n",
    "and red to explain how much different features contributed to the\n",
    "classification, and in which direction (Example **?@exm-eli5b**).\n",
    "\n",
    "Using eli5 to explain a prediction \\## Python code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
